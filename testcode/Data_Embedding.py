from langchain_community.document_loaders import PyMuPDFLoader, UnstructuredWordDocumentLoader, UnstructuredExcelLoader, \
    UnstructuredCSVLoader
from langchain.text_splitter import SpacyTextSplitter
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
import spacy
from pinecone import Pinecone
from langchain.schema import Document

import os
import olefile
import pandas as pd
import docx2txt
from dotenv import load_dotenv
import shutil

load_dotenv()

# ğŸ”¹ 1. ì—¬ëŸ¬ ê°œì˜ ë¬¸ì„œ ì²˜ë¦¬í•˜ê¸°
data_directory = "/Users/ellie/Desktop/ì•„ì£¼ì±—ë´‡ Data"  # ë°ì´í„°ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
max_files = 10  # ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ ê°œìˆ˜
documents = []


# ğŸ”¹ 2. íŒŒì¼ í™•ì¥ìë³„ ë¡œë“œ í•¨ìˆ˜
def load_hwp(file_path):
    """HWP íŒŒì¼ì„ OLE ë°©ì‹ìœ¼ë¡œ ì½ì–´ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        with olefile.OleFileIO(file_path) as hwp:
            if hwp.exists('HwpSummaryInformation'):
                meta = hwp.get_metadata()
                text = meta.summary if meta.summary else "í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                return [Document(page_content=text, metadata={"source": file_path})]
            else:
                return [Document(page_content="í•´ë‹¹ HWP íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", metadata={"source": file_path})]
    except Exception as e:
        return [Document(page_content=f"HWP íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}", metadata={"source": file_path})]


def load_docx(file_path):
    """DOCX íŒŒì¼ ë¡œë“œ"""
    text = docx2txt.process(file_path)
    return [Document(page_content=text, metadata={"source": file_path})]


def load_xlsx(file_path):
    """XLSX íŒŒì¼ ë¡œë“œ"""
    df = pd.read_excel(file_path)
    text = df.to_string()  # ì—‘ì…€ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
    return [Document(page_content=text, metadata={"source": file_path})]


def load_csv(file_path):
    """CSV íŒŒì¼ ë¡œë“œ"""
    df = pd.read_csv(file_path)
    text = df.to_string()  # CSV ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
    return [Document(page_content=text, metadata={"source": file_path})]


def load_pdf(file_path):
    """PDF íŒŒì¼ ë¡œë“œ"""
    loader = PyMuPDFLoader(file_path)
    pdf_documents = loader.load()

    # PyMuPDFLoaderëŠ” ì´ë¯¸ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
    return pdf_documents


# ğŸ”¹ 3. íŒŒì¼ í™•ì¥ìë³„ë¡œ ë¬¸ì„œ ë¡œë“œ
file_list = os.listdir(data_directory)[:max_files]

for filename in file_list:
    file_path = os.path.join(data_directory, filename)

    if filename.endswith(".pdf"):
        documents.extend(load_pdf(file_path))
    elif filename.endswith(".hwp"):
        documents.extend(load_hwp(file_path))
    elif filename.endswith(".docx"):
        documents.extend(load_docx(file_path))
    elif filename.endswith(".xlsx"):
        documents.extend(load_xlsx(file_path))
    elif filename.endswith(".csv"):
        documents.extend(load_csv(file_path))

print(f"ì´ {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")


# ğŸ”¹ 4. ë¬¸ì„œ ë¶„í• 
# Spacy ëª¨ë¸ ë¡œë“œ ë° max_length ì„¤ì •
nlp = spacy.load("ko_core_news_sm")
nlp.max_length = 2_000_000

text_splitter = SpacyTextSplitter(
    chunk_size=300,
    pipeline="ko_core_news_sm",
    max_length = 2000000,
    separator="\n\n"
)
splitted_documents = text_splitter.split_documents(documents)

print(f"ì´ {len(splitted_documents)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ğŸ”¹ 5. OpenAI Embeddings ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings(
    model="text-embedding-ada-002",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# ğŸ”¹ 6. Pinecone ì´ˆê¸°í™”
pinecone_client = Pinecone(
    api_key=os.getenv("PINECONE_API_KEY")
)

# ğŸ”¹ 7. Pinecone VectorStore ì´ˆê¸°í™” ë° ë¬¸ì„œ ì¶”ê°€
index_name = "ajou-data"
vectorstore = PineconeVectorStore(
    embedding=embeddings,
    index_name=index_name,
    namespace="your_namespace"
)

vectorstore.add_documents(splitted_documents)  # ğŸ”¹ ëª¨ë“  ë¬¸ì„œ í•œ ë²ˆì— ì—…ë¡œë“œ

print("âœ… ëª¨ë“  ë¬¸ì„œë¥¼ Pinecone ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì™„ë£Œ!")


# 8. ì™„ë£Œ ë¬¸ì„œ ì´ë™
processed_data_directory = "/Users/ellie/Desktop/Done"  # ì´ë™í•  í´ë” ê²½ë¡œ

if not os.path.exists(processed_data_directory):
    os.makedirs(processed_data_directory)  # í´ë” ì—†ìœ¼ë©´ ìƒì„±

for filename in file_list:
    file_path = os.path.join(data_directory, filename)
    new_path = os.path.join(processed_data_directory, filename)

    shutil.move(file_path, new_path)  # íŒŒì¼ ì´ë™
    print(f"ğŸ“‚ íŒŒì¼ ì´ë™ ì™„ë£Œ: {filename} â†’ {new_path}")
